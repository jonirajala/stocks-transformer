{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_stocks_5yr.csv').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = df.groupby(\"Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11776, 50, 5]) torch.Size([505, 50, 5])\n"
     ]
    }
   ],
   "source": [
    "train_prices = []\n",
    "test_prices = []\n",
    "features = ['open', 'volume', 'high', 'low', 'close']\n",
    "for name, company_df in companies:\n",
    "    for i in range(0, len(company_df) - block_size + 1, block_size):\n",
    "        block = company_df.iloc[i:i+block_size][features]\n",
    "        train_prices.append(block.values.tolist())\n",
    "    test_prices.append(train_prices.pop())\n",
    "train_prices = torch.tensor(train_prices)\n",
    "test_prices = torch.tensor(test_prices)\n",
    "\n",
    "# Reshape to 2D for scaling\n",
    "train_prices_flat = train_prices.view(-1, len(features))\n",
    "test_prices_flat = test_prices.view(-1, len(features))\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "train_prices_scaled_flat = scaler.fit_transform(train_prices_flat)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "test_prices_scaled_flat = scaler.transform(test_prices_flat)\n",
    "\n",
    "# Reshape back to the original shape\n",
    "train_prices_scaled = torch.tensor(train_prices_scaled_flat, dtype=torch.float32).view(train_prices.shape)\n",
    "test_prices_scaled = torch.tensor(test_prices_scaled_flat, dtype=torch.float32).view(test_prices.shape)\n",
    "\n",
    "print(train_prices_scaled.shape, test_prices_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from torchtune.modules import RMSNorm, RotaryPositionalEmbeddings\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        scaled_hidden = int(2 / 3 * 4 * config.emb_dim)\n",
    "        self.fc1 = nn.Linear(config.emb_dim, scaled_hidden, bias=False)\n",
    "        self.fc2 = nn.Linear(config.emb_dim, scaled_hidden, bias=False)\n",
    "        self.fc3 = nn.Linear(scaled_hidden, config.emb_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        hidden = F.silu(x1)\n",
    "        hidden = hidden * x2\n",
    "        return self.fc3(hidden)\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.emb_dim % config.n_head == 0\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.n_head = config.n_head\n",
    "        self.head_dim = config.emb_dim // config.n_head\n",
    "\n",
    "        self.Wq = nn.Linear(config.emb_dim, self.n_head * self.head_dim, bias=False)\n",
    "        self.Wk = nn.Linear(config.emb_dim, self.n_head * self.head_dim, bias=False)\n",
    "        self.Wv = nn.Linear(config.emb_dim, self.n_head * self.head_dim, bias=False)\n",
    "        self.Wo = nn.Linear(config.emb_dim, self.n_head * self.head_dim, bias=False)\n",
    "        self.register_buffer(\n",
    "            \"bias\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size)).view(\n",
    "                1, 1, config.block_size, config.block_size\n",
    "            ),\n",
    "        )\n",
    "        self.pos_emb = RotaryPositionalEmbeddings(self.head_dim, config.block_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, dim = x.shape\n",
    "        assert dim == self.emb_dim, \"dim must be equal to self.emb_dim\"\n",
    "\n",
    "        xq = self.Wq(x)\n",
    "        xk = self.Wk(x)\n",
    "        xv = self.Wv(x)\n",
    "\n",
    "        xq = xq.view(batch_size, seq_len, self.n_head, self.head_dim)\n",
    "        xk = xk.view(batch_size, seq_len, self.n_head, self.head_dim)\n",
    "        xv = xv.view(batch_size, seq_len, self.n_head, self.head_dim)\n",
    "\n",
    "        xq = self.pos_emb(xq)\n",
    "        xk = self.pos_emb(xk)\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = xk.transpose(1, 2)\n",
    "        values = xv.transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(xq, keys.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        scores = scores.masked_fill(\n",
    "            self.bias[:, :, :seq_len, :seq_len] == 0, float(\"-inf\")\n",
    "        )\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        context = torch.matmul(scores, values)\n",
    "\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, -1)\n",
    "        output = self.Wo(context)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.rn1 = RMSNorm(config.emb_dim)\n",
    "        self.rn2 = RMSNorm(config.emb_dim)\n",
    "        self.attn = MultiHeadSelfAttention(config)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.rn1(x))\n",
    "        x = x + self.mlp(self.rn2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LLama(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # self.inp_emb = nn.Embedding(config.vocab_size, config.emb_dim)\n",
    "        self.inp_emb = nn.Linear(config.num_features, config.emb_dim)\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layers)])\n",
    "        self.fc_out = nn.Linear(config.emb_dim, 1, bias=False)\n",
    "        self.rmsnorm = RMSNorm(config.emb_dim)\n",
    "        # self.inp_emb.weight = self.fc_out.weight # https://paperswithcode.com/method/weight-tying\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        batch, seq_len, features = x.shape\n",
    "        x = self.inp_emb(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.rmsnorm(x)\n",
    "\n",
    "        logits = self.fc_out(x)\n",
    "        loss = None\n",
    "        # print(logits.view(-1).squeeze().shape, y.view(-1).shape)\n",
    "        logits = logits.squeeze()\n",
    "        print(logits.shape, y.shape)\n",
    "        if y is not None:\n",
    "            loss = F.mse_loss(\n",
    "                logits.view(-1).squeeze(), y.view(-1), reduction='mean'\n",
    "            )\n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, inp, temperature=1.0, top_k=None):\n",
    "        inp = inp.reshape(1, -1)\n",
    "        for _ in range(self.config.block_size - inp.shape[1]):\n",
    "            logits, _ = self.forward(inp)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            inp_next = torch.multinomial(probs, num_samples=1)\n",
    "            inp = torch.cat((inp, inp_next), dim=1)\n",
    "        return inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(\n",
    "        self, num_features, emb_dim, n_layers, n_head, block_size, top_k=None):\n",
    "        self.block_size = block_size\n",
    "        self.window_size = self.block_size // 2\n",
    "        self.batch_size = 32\n",
    "        self.iters = 1000\n",
    "        self.dropout = 0.1\n",
    "        self.n_kv_heads = 8\n",
    "        self.num_features = num_features\n",
    "        self.top_k = top_k\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_head = n_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 49]) torch.Size([32, 49])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[252], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m x_train \u001b[38;5;241m=\u001b[39m train_prices_scaled[start_idx:end_idx]\n\u001b[1;32m     18\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m logits, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/fun/joni-simons/vevn/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/joni-simons/vevn/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[250], line 115\u001b[0m, in \u001b[0;36mLLama.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[0;32m--> 115\u001b[0m         logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(), \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, loss\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "config = Config(len(features), 512, 8, 8, block_size)\n",
    "model = LLama(config)\n",
    "model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "iters = 100\n",
    "batch_size = 32\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_batches = len(train_prices_scaled) // batch_size\n",
    "\n",
    "for i in range(iters):\n",
    "    batch_index = i % num_batches\n",
    "    \n",
    "    start_idx = batch_index * batch_size\n",
    "    end_idx = (batch_index + 1) * batch_size\n",
    "    x_train = train_prices_scaled[start_idx:end_idx]\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    \n",
    "    logits, train_loss = model(x_train[:, :-1, :], x_train[:, 1:, 0])\n",
    "    \n",
    "    train_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        with torch.no_grad():\n",
    "            x_test = test_prices_scaled\n",
    "            _, test_loss = model(x_test[:, :-1, :], x_test[:, 1:, 0])\n",
    "            test_losses.append((i, test_loss.item()))\n",
    "        print(train_loss.item(), test_loss.item())\n",
    "\n",
    "\n",
    "test_loss_indices, test_loss_values = zip(*test_losses)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(iters), train_losses, label='Training Loss')\n",
    "plt.plot(test_loss_indices, test_loss_values, label='Testing Loss', marker='o')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
